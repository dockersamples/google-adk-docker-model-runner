# Google ADK Docker Model Runner Configuration
# Copy this file to .env and update the values

# ====================
# Docker Model Runner Configuration
# ====================

# FIXED: This environment variable is now actually used by the code!
# Docker Model Runner endpoint (auto-detected if not set)
# For containers: http://host.docker.internal:12434/engines/llama.cpp/v1
# For localhost: http://localhost:12434/engines/llama.cpp/v1
DOCKER_MODEL_RUNNER=

# Model to use (automatically prefixed with openai/ for Docker Model Runner)
MODEL_NAME=ai/llama3.2:1B-Q8_0

# API key for local model runner (can be anything)
OPENAI_API_KEY=anything

# ====================
# Google Cloud / Gemini Configuration (for Google Search agents)
# ====================

# Required for Google Search agents that use Gemini
GOOGLE_API_KEY=XXXX

# Google Cloud settings
GOOGLE_GENAI_USE_VERTEXAI=FALSE
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_CLOUD_PROJECT=XXXX

# ====================
# Agent Configuration
# ====================

# Default test query for agents
TEST_QUERY=Create a responsive HTML landing page with navigation

# Agent type to run (sequential, parallel, loop, human_in_loop, google_search, find_job)
AGENT_TYPE=sequential

# Human feedback scenario for human-in-loop agent (0-3)
HUMAN_FEEDBACK_SCENARIO=0

# ====================
# Development Settings
# ====================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable development mode features
DEV_MODE=true